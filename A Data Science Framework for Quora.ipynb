{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f9622945156d6337ba73c481da2de7efef7384"
   },
   "source": [
    "# <div style=\"text-align: center\">A Data Science Framework for Quora </div>\n",
    "### <div align=\"center\"><b>Quite Practical and Far from any Theoretical Concepts</b></div>\n",
    "<img src='http://s9.picofile.com/file/8342477368/kq.png'>\n",
    "<div style=\"text-align:center\">last update: <b>19/01/2019</b></div>\n",
    "\n",
    "You can Fork and Run this kernel on **Github**:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "750903cc2679d39058f56df6c6c040be02b748df"
   },
   "source": [
    " <a id=\"1\"></a> <br>\n",
    "## 1- Introduction\n",
    "<font color=\"red\">Quora</font> has defined a competition in **Kaggle**. A realistic and attractive data set for data scientists.\n",
    "on this notebook, I will provide a **comprehensive** approach to solve Quora classification problem for **beginners**.\n",
    "\n",
    "I am open to getting your feedback for improving this **kernel**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cda11210a88d6484112cbe2c3624225328326c6a"
   },
   "source": [
    "<a id=\"top\"></a> <br>\n",
    "## Notebook  Content\n",
    "1. [Introduction](#1)\n",
    "1. [Data Science Workflow for Quora](#2)\n",
    "1. [Problem Definition](#3)\n",
    "    1. [Business View](#31)\n",
    "        1. [Real world Application Vs Competitions](#311)\n",
    "    1. [What is a insincere question?](#32)\n",
    "    1. [How can we find insincere question?](#33)\n",
    "1. [Problem feature](#4)\n",
    "    1. [Aim](#41)\n",
    "    1. [Variables](#42)\n",
    "    1. [ Inputs & Outputs](#43)\n",
    "1. [Select Framework](#5)\n",
    "    1. [Import](#51)\n",
    "    1. [Version](#52)\n",
    "    1. [Setup](#53)\n",
    "1. [Exploratory data analysis](#6)\n",
    "    1. [Data Collection](#61)\n",
    "        1. [Features](#611)\n",
    "        1. [Explorer Dataset](#612)\n",
    "    1. [Data Cleaning](#62)\n",
    "    1. [Data Preprocessing](#63)\n",
    "        1. [Is data set imbalance?](#631)\n",
    "        1. [Some Feature Engineering](#632)\n",
    "    1. [Data Visualization](#64)\n",
    "        1. [countplot](#641)\n",
    "        1. [pie plot](#642)\n",
    "        1. [Histogram](#643)\n",
    "        1. [violin plot](#645)\n",
    "        1. [kdeplot](#646)\n",
    "1. [Apply Learning](#7)\n",
    "1. [Conclusion](#8)\n",
    "1. [References](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9438d850fcacb93c4dc1f7873255803ecbf521c"
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated**\n",
    " \n",
    " -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e11b73b618b0f6e4335520ef80267c6d577d1ba5"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 2- A Data Science Workflow for Quora\n",
    "Of course, the same solution can not be provided for all problems, so the best way is to create a **general framework** and adapt it to new problem.\n",
    "\n",
    "**You can see my workflow in the below image** :\n",
    "\n",
    " <img src=\"http://s8.picofile.com/file/8342707700/workflow2.png\"  />\n",
    "\n",
    "**You should feel free\tto\tadjust \tthis\tchecklist \tto\tyour needs**\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "600be852c0d28e7c0c5ebb718904ab15a536342c"
   },
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## 3- Problem Definition\n",
    "I think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n",
    "> **we will be predicting whether a question asked on Quora is sincere or not.**\n",
    "<a id=\"31\"></a> <br>\n",
    "## 3-1 About Quora\n",
    "Quora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n",
    "<a id=\"32\"></a> <br>\n",
    "## 3-2 Business View \n",
    "An existential problem for any major website today is how to handle toxic and divisive content. **Quora** wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.\n",
    "\n",
    "**Quora** is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n",
    "\n",
    "In this kernel, I will develop models that identify and flag insincere questions.we Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.\n",
    "<a id=\"321\"></a> <br>\n",
    "### 3-2-1 Real world Application Vs Competitions\n",
    "Just a simple comparison between real-world apps with competitions:\n",
    "<img src=\"http://s9.picofile.com/file/8339956300/reallife.png\" height=\"600\" width=\"500\" />\n",
    "<a id=\"33\"></a> <br>\n",
    "## 3-3 What is a insincere question?\n",
    "Is defined as a question intended to make a **statement** rather than look for **helpful answers**.\n",
    "<img src='http://s8.picofile.com/file/8342711526/Quora_moderation.png'>\n",
    "<a id=\"34\"></a> <br>\n",
    "## 3-4 How can we find insincere question?\n",
    "Some characteristics that can signify that a question is insincere:\n",
    "\n",
    "1. **Has a non-neutral tone**\n",
    "    1. Has an exaggerated tone to underscore a point about a group of people\n",
    "    1. Is rhetorical and meant to imply a statement about a group of people\n",
    "1. **Is disparaging or inflammatory**\n",
    "    1. Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
    "    1. Makes disparaging attacks/insults against a specific person or group of people\n",
    "    1. Based on an outlandish premise about a group of people\n",
    "    1. Disparages against a characteristic that is not fixable and not measurable\n",
    "1. **Isn't grounded in reality**\n",
    "    1. Based on false information, or contains absurd assumptions\n",
    "    1. Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n",
    "    ###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "556980c672d2f7b2a4ee943b9d13b88de6e41e04"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "## 4- Problem Feature\n",
    "Problem Definition has three steps that have illustrated in the picture below:\n",
    "\n",
    "1. Aim\n",
    "1. Variable\n",
    "1. Inputs & Outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"41\"></a> <br>\n",
    "### 4-1 Aim\n",
    "We will be predicting whether a question asked on Quora is **sincere** or not.\n",
    "\n",
    "\n",
    "<a id=\"42\"></a> <br>\n",
    "### 4-2 Variables\n",
    "\n",
    "1. qid - unique question identifier\n",
    "1. question_text - Quora question text\n",
    "1. target - a question labeled \"insincere\" has a value of 1, otherwise 0\n",
    "\n",
    "<a id=\"43\"></a> <br>\n",
    "### 4-3 Inputs & Outputs\n",
    "we use train.csv and test.csv as Input and we should upload a  submission.csv as Output\n",
    "\n",
    "\n",
    "**<< Note >>**\n",
    "> You must answer the following question:\n",
    "How does your company expect to use and benefit from **your model**.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbedcae8843986c2139f18dad4b5f313e6535ac5"
   },
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "## 5- Select Framework\n",
    "After problem definition and problem feature, we should select our framework to solve the problem.\n",
    "What we mean by the framework is that  the programming languages you use and by what modules the problem will be solved.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c90e261f3b150e10aaec1f34ab3be768acf7aa25"
   },
   "source": [
    "<a id=\"52\"></a> <br>\n",
    "## 5-2 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud as wc\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "import sklearn\n",
    "import string\n",
    "import scipy\n",
    "import numpy\n",
    "import nltk\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jagap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c2beac253f7ddddcc2e1aa26dc850d5b87268f3"
   },
   "source": [
    "<a id=\"53\"></a> <br>\n",
    "## 5-3 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9ffe2f1e5995150c8138f9e98509c7525fb230b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.1.3\n",
      "sklearn: 0.22.1\n",
      "scipy: 1.4.1\n",
      "seaborn: 0.10.0\n",
      "pandas: 1.0.1\n",
      "numpy: 1.18.1\n",
      "Python: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('Python: {}'.format(sys.version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "431bf889ae401c1089a13835356c13f2b6a06f6c"
   },
   "source": [
    "<a id=\"54\"></a> <br>\n",
    "## 5-4 Setup\n",
    "\n",
    "A few tiny adjustments for better **code readability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8645feedee1145c2df1268a697b0b8773858ad1a"
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5048b61a4837c8826551c8871609973ebbe3847"
   },
   "source": [
    "<a id=\"55\"></a> <br>\n",
    "## 5-5 NLTK\n",
    "In this kernel, we use the NLTK library So, before we begin the next step, we will first introduce this library.\n",
    "<img src='https://arts.unimelb.edu.au/__data/assets/image/0005/2735348/nltk.jpg' width=300 height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "adadeb7a83d0bc711a779948197c40841b10f1ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04ff1a533119d589baee777c21194a951168b0c7"
   },
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "## 6- EDA\n",
    "By the end of the section, you'll be able to answer these questions and more, while generating graphics that are both insightful and beautiful.  then We will review analytical and statistical operations:\n",
    "\n",
    "1. Data Collection\n",
    "1. Visualization\n",
    "1. Data Cleaning\n",
    "1. Data Preprocessing\n",
    "<img src=\"http://s9.picofile.com/file/8338476134/EDA.png\" width=400 height=400>\n",
    "\n",
    " ###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cedecea930b278f86292367cc28d2996a235a169"
   },
   "source": [
    "<a id=\"61\"></a> <br>\n",
    "## 6-1 Data Collection\n",
    "I start Collection Data by the training and testing datasets into **Pandas DataFrames**.\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jagap\\\\Desktop\\\\Python Tutorial\\\\Data Science\\\\5- Big Data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9269ae851b744856bce56840637030a16a5877e1"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\jagap\\Desktop\\Python Tutorial\\Data Science\\input\\input\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\jagap\\Desktop\\Python Tutorial\\Data Science\\input\\input\\test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ed9c838069f54de5cf90b20a774c3e236149b3"
   },
   "source": [
    "**<< Note 1 >>**\n",
    "\n",
    "* Each **row** is an observation (also known as : sample, example, instance, record).\n",
    "* Each **column** is a feature (also known as: Predictor, attribute, Independent Variable, input, regressor, Covariate).\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4708d70e39d1ae861bbf34411cf03d07f261fceb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Douglas Bullen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                      Name   Sex  Age  \\\n",
       "846          847         0       3  Sage, Mr. Douglas Bullen  male  NaN   \n",
       "\n",
       "     SibSp  Parch    Ticket   Fare Cabin Embarked  \n",
       "846      8      2  CA. 2343  69.55   NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f8e7a84ab982504d7263b1812fa66bba78bddbdc"
   },
   "outputs": [],
   "source": [
    "test.sample(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3483fbc1e932d9f387703a796248963e77cefa1d"
   },
   "source": [
    "Or you can use others command to explorer dataset, such as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "08a94b16129d4c231b64d4691374e18aa80f1d80"
   },
   "outputs": [],
   "source": [
    "train.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "581b90e6a869c3793472c7edd59091d6d6342fb2"
   },
   "source": [
    "<a id=\"611\"></a> <br>\n",
    "## 6-1-1 Features\n",
    "Features can be from following types:\n",
    "* numeric\n",
    "* categorical\n",
    "* ordinal\n",
    "* datetime\n",
    "* coordinates\n",
    "\n",
    "Find the type of features in **Qoura dataset**?!\n",
    "\n",
    "For getting some information about the dataset you can use **info()** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ca840f02925751186f87e402fcb5f637ab1ab8a0"
   },
   "outputs": [],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4cbcf76344a6e3c8e841ccf1f43bf00d040a06a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73ab30f86273b590a51fc363d9bf78c2709558fa"
   },
   "source": [
    "<a id=\"612\"></a> <br>\n",
    "## 6-1-2 Explorer Dataset\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4b45251be7be77333051fe738639104ae1005fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (891, 12)\n",
      "Shape of test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# shape for train and test\n",
    "print('Shape of train:',train.shape)\n",
    "print('Shape of test:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c64e9d3e0bf394fb833de94a0fc5c34f69fce24c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10692"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns*rows\n",
    "train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b5fd1034cd591ebd29fba1c77d342ec2b408d13"
   },
   "source": [
    "After loading the data via **pandas**, we should checkout what the content is, description and via the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "edd043f8feb76cfe51b79785302ca4936ceb7b51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1b8b6f0c962a59e5258e74ed9e740a4aaf7c8113"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c288c3dc8656a872a8529368812546e434d3a22"
   },
   "source": [
    "To pop up 5 random rows from the data set, we can use **sample(5)**  function and find the type of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "09eb18d1fcf4a2b73ba2f5ddce99dfa521681140"
   },
   "outputs": [],
   "source": [
    "train.sample(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8280749a19af32869978c61941d1dea306632d71"
   },
   "source": [
    "<a id=\"62\"></a> <br>\n",
    "## 6-2 Data Cleaning\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6315bf510cecb907b2d23aad25faf6ccad32ac4"
   },
   "source": [
    "How many NA elements in every column!!\n",
    "\n",
    "Good news, it is Zero!\n",
    "\n",
    "To check out how many null info are on the dataset, we can use **isnull().sum()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "675f72fb58d83c527f71819e71ed8e17f81126f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5faa6528c6667060c05268757ff46e211b4fea3f"
   },
   "source": [
    "But if we had , we can just use **dropna()**(be careful sometimes you should not do this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e8e124ca20643ad307d9bfdc34328d548c6ddcbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Droping (891, 12)\n",
      "After Droping (183, 12)\n"
     ]
    }
   ],
   "source": [
    "# remove rows that have NA's\n",
    "print('Before Droping',train.shape)\n",
    "train = train.dropna()\n",
    "print('After Droping',train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "277e1998627d6a3ddeff4e913a6b8c3dc81dec96"
   },
   "source": [
    "\n",
    "We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2f1eaf0b6dfdc7cc4dace04614e99ed56425d00"
   },
   "source": [
    "To print dataset **columns**, we can use columns atribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "909d61b33ec06249d0842e6115597bbacf21163f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3458838205be4c7fbff88e95ef69934e13e2199b"
   },
   "source": [
    "You see number of unique item for Target  with command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c7937700664991b29bdb0b3f04942c59498da760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = train['Survived'].values\n",
    "train_target\n",
    "\n",
    "#np.unique(train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d824cb29e135dc5ae98964e71ec0adc0e05ebd43"
   },
   "source": [
    "YES, quora problem is a **binary classification**! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae08b544a8d4202c7d0a47ec83d685e81c91a66d"
   },
   "source": [
    "To check the first 5 rows of the data set, we can use head(5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5899889553c3416b27e93efceddb106eb71f5156"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1150b6ac3d82562aefd5c64f9f01accee5eace4d"
   },
   "source": [
    "Or to check out last 5 row of the data set, we use tail() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "79339442ff1f53ae1054d794337b9541295d3305"
   },
   "outputs": [],
   "source": [
    "train.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8a1cc36348c68fb98d6cb28aa9919fc5f2892f3"
   },
   "source": [
    "To give a **statistical summary** about the dataset, we can use **describe()**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3f7211e96627b9a81c5b620a9ba61446f7719ea3"
   },
   "outputs": [],
   "source": [
    "train.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10bdb8246f66c14043392806cae714f688cc8251"
   },
   "source": [
    "As you can see, the statistical information that this command gives us is not suitable for this type of data\n",
    "**describe() is more useful for numerical data sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c8c838f497c66a227975fb9a2f588e431f0c568"
   },
   "source": [
    "**<< Note 2 >>**\n",
    "in pandas's data frame you can perform some query such as \"where\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c8c8d9fd63d9bdb601183aeb4f1435affeb8a596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    123\n",
       "Survived       123\n",
       "Pclass         123\n",
       "Name           123\n",
       "Sex            123\n",
       "Age            123\n",
       "SibSp          123\n",
       "Parch          123\n",
       "Ticket         123\n",
       "Fare           123\n",
       "Cabin          123\n",
       "Embarked       123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.where(train ['Survived']==1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33fc33a18489b438a884819d99dc00a02b113be8"
   },
   "source": [
    "As you can see in the below in python, it is so easy perform some query on the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8b545ff7e8367c5ab9c1db710f70b6936ac8422c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Survived']>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2788d023986eca622f7db9e1d64c2a4e02737ddb"
   },
   "source": [
    "Some examples of questions that they are insincere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d517b2b99a455a6b89c238faf1647515b8a67d87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "21           22         1       2   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "21                              Beesley, Mr. Lawrence    male  34.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  \n",
       "21      0    248698  13.0000   D56        S  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Survived']==1].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b67d109a0cec1a5475b863bbce8aa3ac9d2d4fb"
   },
   "source": [
    "<a id=\"631\"></a> <br>\n",
    "## 6-3-1 Is data set imbalance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4218d492753322c50142021833efb24cfdfc6ad3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6721311475409836"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e058f90ca403f00d91d0405a7d8822dc7d6de55"
   },
   "source": [
    "A large part of the data is unbalanced, but **how can we  solve it?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "dc6340ee1b637d192e29cbc8d3744ae6351b9c8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    123\n",
       "0     60\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Survived\"].value_counts()\n",
    "# data is imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "873b2cfdee04b8ba087df1c4bf01ae69ef2f1c52"
   },
   "source": [
    "<a id=\"632\"></a> <br>\n",
    "## 6-3-2 Exploreing Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e445c859d7c43857cfbf370ff20060a5341d3c89"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'question_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'question_text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ee344c2f9e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m':'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'question_text'"
     ]
    }
   ],
   "source": [
    "question = train['question_text']\n",
    "i=0\n",
    "for q in question[:5]:\n",
    "    i=i+1\n",
    "    print('sample '+str(i)+':' ,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "fa78f61df85a9c76bd092dbf6d6bcec4b6b2631f"
   },
   "outputs": [],
   "source": [
    "text_withnumber = train['question_text']\n",
    "result = ''.join([i for i in text_withnumber if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c50c6c2683c5c08a6c9c34b75be61567d5993fa0"
   },
   "source": [
    "<a id=\"632\"></a> <br>\n",
    "## 6-3-2 Some Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c641754f26e07c368596af3054268f1b3b764921"
   },
   "source": [
    "[NLTK](https://www.nltk.org/) is one of the leading platforms for working with human language data and Python, the module NLTK is used for natural language processing. NLTK is literally an acronym for Natural Language Toolkit.\n",
    "\n",
    "We get a set of **English stop** words using the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "10ca7d56255b95fc774fff5adf7b4273ec7a1ea2"
   },
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "eng_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f5af107041b279ce723761f37f4ffebae2b22a3"
   },
   "source": [
    "The returned list stopWords contains **179 stop words**  on my computer.\n",
    "You can view the length or contents of this array with the lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "eca2d53bfae70c55b3b5b0e2c244826465cb478b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "{'or', \"you'll\", 'down', 'over', 'from', 'couldn', 'yours', 'her', \"you'd\", 'above', 'same', 'there', 'but', 'isn', 'ourselves', 'him', \"she's\", 'which', 'their', 'wasn', 'nor', \"isn't\", 'shouldn', 'that', 'during', 'have', 'o', 'these', \"you're\", 'his', 'too', 'few', 'theirs', 'being', 'mustn', 'only', \"mightn't\", 'myself', 'themselves', 'am', 'a', 'after', 't', 'been', 'below', 'up', 'll', 'those', 'having', 'wouldn', 'my', 'yourself', 'just', 'before', 'on', 'what', 'each', 'ain', 'we', \"haven't\", 'here', \"should've\", 'has', 'now', 'ma', 'to', 'doesn', 'be', \"hadn't\", \"that'll\", 'no', 'won', 'some', 'while', 'until', 'an', 'them', 'both', 'off', 'it', \"shouldn't\", 'through', 'aren', \"wouldn't\", 'out', \"weren't\", 'the', 'she', 'very', 'in', 'most', 'against', \"mustn't\", 'you', 'm', 'i', 'than', 'where', 'weren', 'between', 'again', 'hers', 'when', 'shan', 'because', 'own', 'he', 's', 'hadn', \"needn't\", 'y', 'himself', 'this', 'of', 'how', 'if', 'as', \"hasn't\", 'other', 'into', 'had', 'its', 'are', 'further', 're', 'by', \"aren't\", 'does', 'for', \"it's\", 'whom', 'd', 'under', \"don't\", \"doesn't\", 'doing', 'hasn', 'once', 'they', 'me', 'will', 'were', 'haven', 'ours', 'is', \"wasn't\", 'any', 'about', 'all', 'our', 'then', 'your', \"couldn't\", \"won't\", 'did', \"shan't\", 'do', 'who', 'didn', 'itself', 'was', 'such', \"didn't\", 've', 'so', 'and', 'don', 'should', \"you've\", 'needn', 'with', 'mightn', 'not', 'more', 'herself', 'can', 'yourselves', 'at', 'why'}\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_stopwords))\n",
    "print(eng_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f049c6d9633200496ed97f8066257849b4824da"
   },
   "source": [
    "The metafeatures that we'll create based on  SRK's  EDAs, [sudalairajkumar](http://http://www.kaggle.com/sudalairajkumar/simple-feature-engg-notebook-spooky-author) and [tunguz](https://www.kaggle.com/tunguz/just-some-simple-eda) are:\n",
    "1. Number of words in the text\n",
    "1. Number of unique words in the text\n",
    "1. Number of characters in the text\n",
    "1. Number of stopwords\n",
    "1. Number of punctuations\n",
    "1. Number of upper case words\n",
    "1. Number of title case words\n",
    "1. Average length of the words\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4982fc699bcb147513c247b9f4d86b02902eded"
   },
   "source": [
    "Number of words in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5b29fbd86ab48be6bd84fcac6fb6bca84d4b8792"
   },
   "outputs": [],
   "source": [
    "train[\"num_words\"] = train[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
    "print('maximum of num_words in train',train[\"num_words\"].max())\n",
    "print('min of num_words in train',train[\"num_words\"].min())\n",
    "print(\"maximum of  num_words in test\",test[\"num_words\"].max())\n",
    "print('min of num_words in train',test[\"num_words\"].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83becd8affc2abab2252e065f77c80dc0dcf53be"
   },
   "source": [
    "Number of unique words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "72aebb943122982b891c959fa9fa36224adcb2fc"
   },
   "outputs": [],
   "source": [
    "train[\"num_unique_words\"] = train[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words\"] = test[\"question_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "print('maximum of num_unique_words in train',train[\"num_unique_words\"].max())\n",
    "print('mean of num_unique_words in train',train[\"num_unique_words\"].mean())\n",
    "print(\"maximum of num_unique_words in test\",test[\"num_unique_words\"].max())\n",
    "print('mean of num_unique_words in train',test[\"num_unique_words\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb2719fa417f2c3fabea9b6582081738ecdf678b"
   },
   "source": [
    "Number of characters in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a7029af9cfed9eb2e624d7177887e111a71054ff"
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"num_chars\"] = train[\"question_text\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars\"] = test[\"question_text\"].apply(lambda x: len(str(x)))\n",
    "print('maximum of num_chars in train',train[\"num_chars\"].max())\n",
    "print(\"maximum of num_chars in test\",test[\"num_chars\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ddd289db2420b4f3fee7268fef94926688afd203"
   },
   "source": [
    "Number of stopwords in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "086e229b918087420c33b57c7ad51d6723cf70f7"
   },
   "outputs": [],
   "source": [
    "train[\"num_stopwords\"] = train[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test[\"num_stopwords\"] = test[\"question_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "print('maximum of num_stopwords in train',train[\"num_stopwords\"].max())\n",
    "print(\"maximum of num_stopwords in test\",test[\"num_stopwords\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "428a009f1a3b00b73ec7d6e8558aebc995e42594"
   },
   "source": [
    "Number of punctuations in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "947abd63c51d74dc33c2891fb1e1b9381d9da23c"
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"num_punctuations\"] =train['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test[\"num_punctuations\"] =test['question_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "print('maximum of num_punctuations in train',train[\"num_punctuations\"].max())\n",
    "print(\"maximum of num_punctuations in test\",test[\"num_punctuations\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a93e8fd32c2ff7dffd81f62ff3b6b3a5975d6836"
   },
   "source": [
    "Number of title case words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "82c95fcf5848ca383a6a84501fe74fef371392d1"
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"num_words_upper\"] = train[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test[\"num_words_upper\"] = test[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "print('maximum of num_words_upper in train',train[\"num_words_upper\"].max())\n",
    "print(\"maximum of num_words_upper in test\",test[\"num_words_upper\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bc4c2b642cb8adf12fd6dbb01616079a454d384"
   },
   "source": [
    "Number of title case words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b938bdcfe7c418f5b4d57c9fd21c77d8bf4d3f06"
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"num_words_title\"] = train[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test[\"num_words_title\"] = test[\"question_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "print('maximum of num_words_title in train',train[\"num_words_title\"].max())\n",
    "print(\"maximum of num_words_title in test\",test[\"num_words_title\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c81bb79d34d242f74b8ed650a8998efdb29e38b"
   },
   "source": [
    " Average length of the words in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3058236ff8702754ee4132f7eb705dd54f354af4"
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"mean_word_len\"] = train[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len\"] = test[\"question_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "print('mean_word_len in train',train[\"mean_word_len\"].max())\n",
    "print(\"mean_word_len in test\",test[\"mean_word_len\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c91162602814ba230ab9fe30f9941ac6409133b9"
   },
   "source": [
    "We add some new feature to train and test data set now, print columns agains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "05cae032149a7c79a92a3b2bf80185c483d0e976"
   },
   "outputs": [],
   "source": [
    "print(train.columns)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa882e5bcdc7d5f440489eff75d1d225269655a4"
   },
   "source": [
    "**<< Note >>**\n",
    ">**Preprocessing and generation pipelines depend on a model type**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f453f5a76194116a73ce8ae5c98de980dc8b5758"
   },
   "source": [
    "## What is Tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "b25495da861c8f917ff91c5c9296b954de03983f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'Kaggle']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "mystring = \"I love Kaggle\"\n",
    "mystring2 = \"I'd love to participate in kaggle competitions.\"\n",
    "nltk.word_tokenize(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "cb760f3b6a02e2b4d5f371bb1fb5376f1cf7db88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'d\", 'love', 'to', 'participate', 'in', 'kaggle', 'competitions', '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(mystring2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "055772bd170aa8018aabd85106b76675802c33b3"
   },
   "source": [
    "<a id=\"64\"></a> <br>\n",
    "## 6-4 Data Visualization\n",
    "**Data visualization**  is the presentation of data in a pictorial or graphical format. It enables decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns.\n",
    "\n",
    "> * Two** important rules** for Data visualization:\n",
    ">     1. Do not put too little information\n",
    ">     1. Do not put too much information\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d991f5a4a9e4fffcbcee4a51b3cf1cd95007427"
   },
   "source": [
    "<a id=\"641\"></a> <br>\n",
    "## 6-4-1 CountPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1b54931579ed4e3004369a59fe9c6f23b97719de"
   },
   "outputs": [],
   "source": [
    "ax=sns.countplot(x='target',hue=\"target\", data=train  ,linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))\n",
    "plt.title('Is data set imbalance?');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "eb15e8fed181179a086bf0db7dc21eaabb4eb088"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"target\", hue=\"target\", data=train)\n",
    "plt.title('Is data set imbalance?');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be2b936baaa6dcc2d574a861c75584ed04d3589e"
   },
   "source": [
    "<a id=\"642\"></a> <br>\n",
    "## 6-4-2  Pie Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4a2332f8c87da0a4f8cc31f587ce547470a0d615"
   },
   "outputs": [],
   "source": [
    "\n",
    "ax=train['target'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%' ,shadow=True)\n",
    "ax.set_title('target')\n",
    "ax.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ee5a0017d867f90a5b89a78866582e73ceef5a05"
   },
   "outputs": [],
   "source": [
    "#plt.pie(train['target'],autopct='%1.1f%%')\n",
    " \n",
    "#plt.axis('equal')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbe8c50bcc1b632f42dd249e27a9a7c14517fd29"
   },
   "source": [
    "<a id=\"643\"></a> <br>\n",
    "## 6-4-3  Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e41be26587175bee1bfe63e43eca1dd3f445c082"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,10))\n",
    "train[train['target']==0].num_words.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\n",
    "ax[0].set_title('target= 0')\n",
    "x1=list(range(0,85,5))\n",
    "ax[0].set_xticks(x1)\n",
    "train[train['target']==1].num_words.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\n",
    "ax[1].set_title('target= 1')\n",
    "x2=list(range(0,85,5))\n",
    "ax[1].set_xticks(x2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a7d0a12e7f719781cd09e0d6df6ae1e780a6b1ab"
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train[['target','num_words']].groupby(['target']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('num_words vs target')\n",
    "sns.countplot('num_words',hue='target',data=train,ax=ax[1])\n",
    "ax[1].set_title('num_words:target=0 vs target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7870ad9dc4a007463301513963d6a2c1fe978aa4"
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "train.hist(figsize=(15,20))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e065ebff5374a9ab83df9c099a05962eb3645934"
   },
   "outputs": [],
   "source": [
    "train[\"num_words\"].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0df20cff46a2bcdeef476e797d1535fd66850c4"
   },
   "source": [
    "<a id=\"644\"></a> <br>\n",
    "## 6-4-4 Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "fe8ca6c82ce44d745ad1ebc942826cf03e2d9895"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=train,x=\"target\", y=\"num_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8436fb0e0a159e9136a44dcd3eb9aae65a4a3b8b"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=train,x=\"target\", y=\"num_words_upper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b08771239bf613afa9f89457fdf25c044279940e"
   },
   "source": [
    "<a id=\"645\"></a> <br>\n",
    "## 6-4-5 KdePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "92f2ce0f1ff05002d196522a6a62579f0dba6ef3"
   },
   "outputs": [],
   "source": [
    "sns.FacetGrid(train, hue=\"target\", size=5).map(sns.kdeplot, \"num_words\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a38e752250257db85554f00b9b440e5d968d4c7a"
   },
   "source": [
    "<a id=\"646\"></a> <br>\n",
    "## 6-4-6 BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ede2021504e4c4d9eb53c9428f643f11e827f666"
   },
   "outputs": [],
   "source": [
    "train['num_words'].loc[train['num_words']>60] = 60 #truncation for better visuals\n",
    "axes= sns.boxplot(x='target', y='num_words', data=train)\n",
    "axes.set_xlabel('Target', fontsize=12)\n",
    "axes.set_title(\"Number of words in each class\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "05a3de95dca3933c118bbaca719a7bd6e4c007cd"
   },
   "outputs": [],
   "source": [
    "train['num_chars'].loc[train['num_chars']>350] = 350 #truncation for better visuals\n",
    "\n",
    "axes= sns.boxplot(x='target', y='num_chars', data=train)\n",
    "axes.set_xlabel('Target', fontsize=12)\n",
    "axes.set_title(\"Number of num_chars in each class\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08745636a4aef9797daf0f52610cdd84d6cfd8f7"
   },
   "source": [
    "<a id=\"646\"></a> <br>\n",
    "## 6-4-6 WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "582eb9b3a4e7ba61cea78b803c9fee55326f9940"
   },
   "outputs": [],
   "source": [
    "def generate_wordcloud(text): \n",
    "    wordcloud = wc(relative_scaling = 1.0,stopwords = eng_stopwords).generate(text)\n",
    "    fig,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    ax.margins(x=0, y=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3d192ec8ece7238fdd16327e7a2e81fcaf0ec18c"
   },
   "outputs": [],
   "source": [
    "text =\" \".join(train.question_text)\n",
    "generate_wordcloud(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97adc471c068fbd8d36ca19a4db0d98b0924c731"
   },
   "source": [
    "-----------------\n",
    "<a id=\"8\"></a> <br>\n",
    "# 8- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1adfb5ba84e0f1d8fba58a2fca30546ead095047",
    "collapsed": true
   },
   "source": [
    "This kernel is not completed yet , I have tried to cover all the parts related to the process of **Quora problem** with a variety of Python packages and I know that there are still some problems then I hope to get your feedback to improve it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf3679a51c72dbe2d2549b5fe97e4ac5f1fa0fa0"
   },
   "source": [
    "you can Fork and Run this kernel on **Github**:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    " **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "\n",
    "-----------\n",
    "\n",
    "# 9- References\n",
    "## 9-1 Kaggle's Kernels\n",
    "**In the end , I want to thank all the kernels I've used in this notebook**:\n",
    "1. [SRK](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc)\n",
    "1. [mihaskalic](https://www.kaggle.com/mihaskalic/lstm-is-all-you-need-well-maybe-embeddings-also)\n",
    "1. [artgor](https://www.kaggle.com/artgor/eda-and-lstm-cnn)\n",
    "1. [tunguz](https://www.kaggle.com/tunguz/just-some-simple-eda)\n",
    "\n",
    "## 9-2 Other References\n",
    "\n",
    "1. [Machine Learning Certification by Stanford University (Coursera)](https://www.coursera.org/learn/machine-learning/)\n",
    "\n",
    "1. [Machine Learning A-Z™: Hands-On Python & R In Data Science (Udemy)](https://www.udemy.com/machinelearning/)\n",
    "\n",
    "1. [Deep Learning Certification by Andrew Ng from deeplearning.ai (Coursera)](https://www.coursera.org/specializations/deep-learning)\n",
    "\n",
    "1. [Python for Data Science and Machine Learning Bootcamp (Udemy)](Python for Data Science and Machine Learning Bootcamp (Udemy))\n",
    "\n",
    "1. [Mathematics for Machine Learning by Imperial College London](https://www.coursera.org/specializations/mathematics-machine-learning)\n",
    "\n",
    "1. [Deep Learning A-Z™: Hands-On Artificial Neural Networks](https://www.udemy.com/deeplearning/)\n",
    "\n",
    "1. [Complete Guide to TensorFlow for Deep Learning Tutorial with Python](https://www.udemy.com/complete-guide-to-tensorflow-for-deep-learning-with-python/)\n",
    "\n",
    "1. [Data Science and Machine Learning Tutorial with Python – Hands On](https://www.udemy.com/data-science-and-machine-learning-with-python-hands-on/)\n",
    "1. [imbalanced-dataset](https://www.quora.com/What-is-an-imbalanced-dataset)\n",
    "1. [algorithm-choice](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice)\n",
    "1. [tokenizing-raw-text-in-python](http://jeffreyfossett.com/2014/04/25/tokenizing-raw-text-in-python.html)\n",
    "1. [text-analytics101](http://text-analytics101.rxnlp.com/2014/10/all-about-stop-words-for-text-mining.html)\n",
    "-------------\n",
    "\n",
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff59d6a3d20b8615d9c58f8d4bb6e3160fbd164e"
   },
   "source": [
    "Go to first step: [Course Home Page](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist)\n",
    "\n",
    "Go to next step : [Titanic](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3218340bb7dfc4ab53987820284a5c2b1c34eb45"
   },
   "source": [
    "#### The kernel is not complete and will be updated soon  !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
